

- [x] add gradio
- [ ] more flex gradio 
- [x] add docker-compose
- [ ] add more source 
- [ ] fix code style
- [ ] add more model 
- [ ] giga biba



https://storage.googleapis.com/kaggle-data-sets/4276920/7362604/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20241211%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20241211T214757Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=6ad42eb48ca06aa234a1b8dcafad0fdce26407b66744587c7c8041a8c07e3f8e56dd8ca89350253643bdf4d4bf9466ce5e4ed8569d314ed052a6e76ddb16ac53ddd326ff937cada569966512279733d2f47f2e408362c7ef12c2b7faf76cde54291c27d178ef18519951e4cca341d86b84698f41758ad073cbd676b7efaf26b4498912b565898cf05919841d3d566c16231ce140b1148c8b01ef1b471fff2752de89700c3fb001b507fe5a65ced3b35fe41f898fa48130079b376e35826033047314fe6073f1763abaaa63ada2b0c67c39aa05400c54430dab2af22c21540b2b4a83b94f3f37fab63335ade66e4524aa2ddbb9ec3b3194540a7b4ac58047c125

"""Краткое описание задачи (агрегатор новостей):
 
1. Скачиваем новости из нескольких заданных RSS источников (с использ например feed_monitor.py  github)
2. Конвертируем скачанные html в pdf (например через wkhtmltopdf)
3. передаем (размещаем во входном каталоге) pdf на вход LLM
(скорее всего GPT4All котрый умеет обрабатывать локальные данные)
см Settings - Local Docs Settings
можно попробовать включить Nomic API там же)
4. Загружаем (в GPT4All) LLM  (Mistral например) добавляем Local Docs (источник - каталог где лежат скачанные новости в pdf)
5. Задаем вопрос "Какие сегодня есть события (новости) упоминающие о ФИО" (спортсмен, политик, киноактер и т.п.)
Или просим "Выведи полный текст новостей о ФИО" (чтобы не пересказ а оригинальный текст новости был)
 
6. Пытаемся автоматизировать пункт 4-5 чтобы выборку и запрос можно было делать автоматически (из python скрипта)
 
7. Пытаемся улучшить результаты выборки - подбираем лучшие модели (Mistral, Deepseek, Snoozy... и их вариации 7b, 33b и т.п.)
Подбираем оптимальную формулировку запроса новостей.
Проверяем самостоятельно новости и смотрим какие новости пропущены (их нет в ответе) или неверно сформулированы, что ничего не придумано (все новости из ответа есть в указанных источниках)
 
8. Пытаемся найти-выбрать инструмент(text-generation-webui ? NVidia RTX Chat? OpenAI web API?) аналогичный по возможностям обработки локльных документов GPT4All желательно в исходках на Github с большей управляемостью, расширяемостью, полной автоматизацией и т.д.
 
Желательно наличие GPU для тестов ( в теории конечно можно через RDP или на бесплатном Google Colab там есть ускорители)
 
п.с.
Можете сформулировать свою похожую задачу , главное врзможность практческого использования и более менее объективной оценки качества работы (рекомендательные системы не рассмартиваем т.к. оценка их работы очень субъективна и непроверяема, также требует сбора данных и большого кол-ва пользователей, что невозможно в рамках нашей работы)
 """
